<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Python学习笔记</title>
    <link href="/2021/08/09/python521/"/>
    <url>/2021/08/09/python521/</url>
    
    <content type="html"><![CDATA[<h2 id="111"><a href="#111" class="headerlink" title="111"></a>111</h2>]]></content>
    
    
    <categories>
      
      <category>Python学习笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>wuenda</title>
    <link href="/2021/08/09/1222333/"/>
    <url>/2021/08/09/1222333/</url>
    
    <content type="html"><![CDATA[<h1 id="吴恩达机器学习笔记"><a href="#吴恩达机器学习笔记" class="headerlink" title="吴恩达机器学习笔记"></a>吴恩达机器学习笔记</h1><p>[TOC]</p><h2 id="课程介绍"><a href="#课程介绍" class="headerlink" title="课程介绍"></a>课程介绍</h2><h3 id="机器学习简介"><a href="#机器学习简介" class="headerlink" title="机器学习简介"></a>机器学习简介</h3><ul><li>A computer program is said to $learn$ from experience $E$ with respect to some task $T$ and some performance measure $P$, if its performance on $T$, as measured by $P$, improves with experience $E$.</li><li>主要的机器学习算法：<ul><li><strong>Supervised learning  监督学习</strong></li><li><strong>Unsupervised learning  无监督学习</strong></li><li>Others: <strong>Reinforcement learning</strong> , <strong>Recommender systems</strong>  </li></ul></li><li>It’s more important to understand <strong><em>how to use</em></strong> these tools instead of just knowing them.</li></ul><h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><ul><li><p>555</p><ul><li>House price prediction (<strong>Regression Problem</strong>)<ul><li>Predict continuous valued output (price)</li></ul></li><li>Breast cancer prediction (<strong>Classfication Problem</strong>)<ul><li>Predict a discrete valued output (0 or 1) (Sometimes more than two values)</li><li><strong>Question</strong>: How to deal with an infinite number of features ?<ul><li><strong>Algorithm</strong>: SVM (Support Vector Machine)</li></ul></li></ul></li></ul></li><li><strong>Supervised Learning</strong>: In every example in the data set, we are told what is the “correct answer” that we would have quite liked the algorithms have predicted on that example.</li></ul><h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><ul><li><strong>Clustering Algorithm</strong>: We are given a data set with the same lable or with no lables and we almost know nothing about it, including what to do with it and what does each data point mean.</li><li>Examples :<ul><li>Google News</li><li>Understand Genomics</li><li>Organize Large Computer Clusters</li><li>Social Network Analysis</li><li>Market Segmentation</li><li>Astronomical Data Analysis</li></ul></li></ul><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="单变量线性回归"><a href="#单变量线性回归" class="headerlink" title="单变量线性回归"></a>单变量线性回归</h3><p><strong>假设函数 ( Hypothesis )</strong></p><script type="math/tex; mode=display">h_\theta(x)=\theta_0+\theta_1x</script><p><strong>代价函数 ( Cost function )</strong></p><script type="math/tex; mode=display">J(\theta_0,\theta_1)=\frac{1}{2m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2</script><p><strong>梯度下降算法 ( Gradient descent )</strong></p><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)\quad (j=0,1)</script><script type="math/tex; mode=display">j=0:\quad\frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1)=\frac{1}{m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})</script><script type="math/tex; mode=display">j=1:\quad\frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1)=\frac{1}{m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x^{(i)}</script><script type="math/tex; mode=display">\theta_0:=\theta_0-\alpha\frac{1}{m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})</script><script type="math/tex; mode=display">\theta_1:=\theta_1-\alpha\frac{1}{m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x^{(i)}</script><h3 id="多变量线性回归"><a href="#多变量线性回归" class="headerlink" title="多变量线性回归"></a>多变量线性回归</h3><p><strong>假设函数 ( Hypothesis )</strong></p><script type="math/tex; mode=display">\theta=[\theta_0,\theta_1,\theta_2,\cdots ,\theta_n]^T</script><script type="math/tex; mode=display">x=[x_0,x_1,x_2,\cdots ,x_n]^T\quad (x_0=1)</script><script type="math/tex; mode=display">h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+\cdots +\theta_nx_n=\theta^Tx</script><p><strong>代价函数 ( Cost function )</strong></p><script type="math/tex; mode=display">J(\theta)=J(\theta_0,\theta_1,\cdots ,\theta_n)=\frac{1}{2m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2</script><p><strong>梯度下降算法 ( Gradient descent )</strong></p><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta)</script><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha\frac{1}{m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x^{(i)}_j</script><p><strong>特征缩放 ( Feature scaling )</strong></p><script type="math/tex; mode=display">mean\;\;normalization:\quad x'=\frac{x-averge(x)}{max(x)-min(x)}</script><p><strong>学习率$\;\alpha\;$ ( Learning rate )</strong><br>$(1)\;$判断$J(\theta)$是否收敛的方法:<br>$\qquad I.\;$绘制$minJ(\theta)-No.\;of\;iterations$图像进行判断.<br>$\qquad II.\;$收敛测试.在每次迭代中$J(\theta)$减小的值是否小于$\xi$（$\xi$一般取$10^{-3}$）.<br>$\qquad Tip.\;$推荐使用方法$I$。因为在实际应用中,合适的$\xi$取值是很难选取的.<br>$(2)\;$如果$J(\theta)-No.\;of\;iterations$图像单调递增，可能是因为学习率$\alpha$的取值过大，导致梯度下降算法在最优解附近跳跃。<br>$(3)\;$如果$J(\theta)-No.\;of\;iterations$图像上下波动，应适当减小$\alpha$的取值。<br>$(4)\;$如果$\alpha$的取值过小，可能会导致梯度下降算法的收敛速度过慢 ( baby steps )。<br>$(5)\;$对$\alpha$取值的建议：$\quad\cdots,\ 0.001,\ 0.003,\ 0.01,\ 0.03,\ 0.1,\ 0.3,\ 1,\cdots\quad$( 3 times )。<br><strong>特征的选择 ( Choice of features )</strong><br>$Example1.\;$房价预测：</p><script type="math/tex; mode=display">not\; suitable:\quad h_\theta(x)=\theta_0+\theta_1\times frontage+\theta_2\times depth</script><script type="math/tex; mode=display">why\; not:\quad h_\theta(x)=\theta_0+\theta_1\times area\quad(area=frontage\times depth)</script><p>$Example2.\;$数据拟合：</p><script type="math/tex; mode=display">not\; suitable:\quad h_\theta(x)=\theta_0+\theta_1\times size+\theta_2\times size^2</script><script type="math/tex; mode=display">why\; not:\quad h_\theta(x)=\theta_0+\theta_1\times size+\theta_2\times\sqrt{size}</script><p><strong>多项式回归 ( Polynomial regression )</strong><br>对于函数$\theta_0+\theta_1x+\theta_2x^2+\theta_3x^3$，我们可以令$x_1=x,x_2=x^2,x_3=x^3$，将其转化为线性回归问题进行求解，即：</p><script type="math/tex; mode=display">h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_3</script><p>$Attention.\;$此处进行特征缩放的重要性不言而喻。<br><strong>正规方程 ( Normal equation )</strong></p><script type="math/tex; mode=display">J(\theta_0,\theta_1,\cdots ,\theta_n)=\frac{1}{2m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2</script><script type="math/tex; mode=display">For\;\;every\;\;j:\frac{\partial}{\partial\theta_j}J(\theta)=0</script><script type="math/tex; mode=display">\theta=(X^TX)^{-1}X^Ty</script><p>$Attention.\;$todo</p><h2 id="Logistic回归"><a href="#Logistic回归" class="headerlink" title="Logistic回归"></a>Logistic回归</h2><h3 id="分类问题-Classification-Problem"><a href="#分类问题-Classification-Problem" class="headerlink" title="分类问题(Classification Problem)"></a>分类问题(Classification Problem)</h3><ul><li>分类(Classification):$y\in{0,1}$<ul><li>0: Negative Class</li><li>1: Postive Class</li></ul></li></ul><h3 id="假设函数-Hypothesis-Function"><a href="#假设函数-Hypothesis-Function" class="headerlink" title="假设函数(Hypothesis Function)"></a>假设函数(Hypothesis Function)</h3><ul><li>Linear Regression Hypothesis Function:<script type="math/tex; mode=display">h_\theta(x)=\theta^Tx</script></li><li>Logistic Regression Hypothesis Function:<script type="math/tex; mode=display">h_\theta(x)=g(\theta^Tx)</script></li><li>Logistic Function(Sigmoid Function):<script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script></li><li>即：<script type="math/tex; mode=display">h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}</script></li></ul><h3 id="决策边界-Decision-Boundary"><a href="#决策边界-Decision-Boundary" class="headerlink" title="决策边界(Decision Boundary)"></a>决策边界(Decision Boundary)</h3><p>Logistic回归：</p><script type="math/tex; mode=display">h_\theta(x)=g(\theta^Tx)</script><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><h2 id="神经网络-Neural-Networks"><a href="#神经网络-Neural-Networks" class="headerlink" title="神经网络(Neural Networks)"></a>神经网络(Neural Networks)</h2><h3 id="非线性假设-Non-linear-Hypotheses"><a href="#非线性假设-Non-linear-Hypotheses" class="headerlink" title="非线性假设(Non-linear Hypotheses)"></a>非线性假设(Non-linear Hypotheses)</h3><h3 id="代价函数-Cost-Function"><a href="#代价函数-Cost-Function" class="headerlink" title="代价函数(Cost Function)"></a>代价函数(Cost Function)</h3><p>二元分类(Binary Classfication):$y=0\; or\;1$(1 output unit)<br>多类别分类(Multi-class Classfication):$K$维向量，即$y\in R^K$(K output units)<br><strong>Cost Function</strong>:</p>]]></content>
    
    
    <categories>
      
      <category>CS231n学习笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS231n</tag>
      
      <tag>计算机视觉</tag>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CS231n学习笔记</title>
    <link href="/2021/08/09/cs231n_note/"/>
    <url>/2021/08/09/cs231n_note/</url>
    
    <content type="html"><![CDATA[<h2 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a>Image Classification</h2><h3 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h3><ul><li>Semantic Gap</li><li>Viewpoint Variation</li><li>Illumination</li><li>Deformation</li><li>Occlusion</li><li>Background Clutter</li><li>Intraclass Variation</li></ul>]]></content>
    
    
    <categories>
      
      <category>CS231n学习笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS231n</tag>
      
      <tag>计算机视觉</tag>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python OJ 题解</title>
    <link href="/2021/08/01/pythonOJ/"/>
    <url>/2021/08/01/pythonOJ/</url>
    
    <content type="html"><![CDATA[<h2 id="1000-A-B-Problem"><a href="#1000-A-B-Problem" class="headerlink" title="1000: A+B Problem"></a>1000: A+B Problem</h2><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>计算2个整数a, b的和.这两个整数都在1到1000之间.</p><h3 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h3><p>输入只有一行，包括2个整数a, b.两者之间用一个空格分开.</p><h3 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h3><p>输出只有一行，包括1个整数.必须用print()输出你的结果，才能通过OJ的评判.</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/python3</span><br>a, b = <span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, <span class="hljs-built_in">input</span>().split())<br><span class="hljs-built_in">print</span>(a + b)<br></code></pre></div></td></tr></table></figure><h2 id="1001-Python的Hello-World"><a href="#1001-Python的Hello-World" class="headerlink" title="1001: Python的Hello World"></a>1001: Python的Hello World</h2><h3 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h3><p>请在一行内输出”Python = Pile + sensensen”.</p><h3 id="输入-1"><a href="#输入-1" class="headerlink" title="输入"></a>输入</h3><p>无输入.</p><h3 id="输出-1"><a href="#输出-1" class="headerlink" title="输出"></a>输出</h3><p>按照题目要求输出.</p><h3 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/python3</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Python = Pile + sensensen&quot;</span>)<br></code></pre></div></td></tr></table></figure><h2 id="1002-Python-成绩"><a href="#1002-Python-成绩" class="headerlink" title="1002: Python 成绩"></a>1002: Python 成绩</h2><h3 id="题目描述-2"><a href="#题目描述-2" class="headerlink" title="题目描述"></a>题目描述</h3><p>森森最近学习了Python课，这门课程的总成绩计算方法是：总成绩=作业成绩×20%+小测成绩×30%+期末考试成绩×50%。森森想知道，这门课程自己最终能得到多少分。</p><h3 id="输入-2"><a href="#输入-2" class="headerlink" title="输入"></a>输入</h3><p>输入文件只有1行，包含三个非负整数A、B、C，分别表示森森的作业成绩、小测成绩和期末考试成绩。<br>相邻两个数之间用一个空格隔开，三项成绩满分都是100分。<br>0 ≤ A、 B、 C ≤ 100 且 A、 B、 C 都是 10 的整数倍</p><h3 id="输出-2"><a href="#输出-2" class="headerlink" title="输出"></a>输出</h3><p>输出文件只有1行，包含一个整数，即森森这门课程的总成绩，满分也是100分。</p><h3 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/python3</span><br>a, b, c = <span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, <span class="hljs-built_in">input</span>().split())<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">int</span>(<span class="hljs-number">0.2</span>*a + <span class="hljs-number">0.3</span>*b + <span class="hljs-number">0.5</span>*c))<br></code></pre></div></td></tr></table></figure><h2 id="1003-eval-函数的使用1"><a href="#1003-eval-函数的使用1" class="headerlink" title="1003: eval()函数的使用1"></a>1003: eval()函数的使用1</h2><h3 id="题目描述-3"><a href="#题目描述-3" class="headerlink" title="题目描述"></a>题目描述</h3><p>请在一行内输出”Python = Pile + sensensen”.</p><h3 id="输入-3"><a href="#输入-3" class="headerlink" title="输入"></a>输入</h3><p>无输入.</p><h3 id="输出-3"><a href="#输出-3" class="headerlink" title="输出"></a>输出</h3><p>按照题目要求输出.</p><h3 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/python3</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Python = Pile + sensensen&quot;</span>)<br></code></pre></div></td></tr></table></figure><h2 id="1004-math库的使用"><a href="#1004-math库的使用" class="headerlink" title="1004: math库的使用"></a>1004: math库的使用</h2><h3 id="题目描述-4"><a href="#题目描述-4" class="headerlink" title="题目描述"></a>题目描述</h3><p>森森最近学习了Python课，这门课程的总成绩计算方法是：总成绩=作业成绩×20%+小测成绩×30%+期末考试成绩×50%。森森想知道，这门课程自己最终能得到多少分。</p><h3 id="输入-4"><a href="#输入-4" class="headerlink" title="输入"></a>输入</h3><p>输入文件只有1行，包含三个非负整数A、B、C，分别表示森森的作业成绩、小测成绩和期末考试成绩。<br>相邻两个数之间用一个空格隔开，三项成绩满分都是100分。<br>0 ≤ A、 B、 C ≤ 100 且 A、 B、 C 都是 10 的整数倍</p><h3 id="输出-4"><a href="#输出-4" class="headerlink" title="输出"></a>输出</h3><p>输出文件只有1行，包含一个整数，即森森这门课程的总成绩，满分也是100分。</p><h3 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a>代码</h3><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/python3</span><br>a, b, c = <span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, <span class="hljs-built_in">input</span>().split())<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">int</span>(<span class="hljs-number">0.2</span>*a + <span class="hljs-number">0.3</span>*b + <span class="hljs-number">0.5</span>*c))<br></code></pre></div></td></tr></table></figure><h2 id="1005-字符串存在判定"><a href="#1005-字符串存在判定" class="headerlink" title="1005: 字符串存在判定"></a>1005: 字符串存在判定</h2><h2 id="1006-回文串的判断"><a href="#1006-回文串的判断" class="headerlink" title="1006: 回文串的判断"></a>1006: 回文串的判断</h2><h2 id="1007-成绩分析"><a href="#1007-成绩分析" class="headerlink" title="1007: 成绩分析"></a>1007: 成绩分析</h2><h2 id="1008-最大公约数"><a href="#1008-最大公约数" class="headerlink" title="1008: 最大公约数"></a>1008: 最大公约数</h2><h2 id="1009-输出偶数"><a href="#1009-输出偶数" class="headerlink" title="1009: 输出偶数"></a>1009: 输出偶数</h2><h2 id="1010-计算均值"><a href="#1010-计算均值" class="headerlink" title="1010: 计算均值"></a>1010: 计算均值</h2><h2 id="1011-计算阶乘"><a href="#1011-计算阶乘" class="headerlink" title="1011: 计算阶乘"></a>1011: 计算阶乘</h2><h2 id="1012-汇率兑换"><a href="#1012-汇率兑换" class="headerlink" title="1012: 汇率兑换"></a>1012: 汇率兑换</h2><h2 id="1013-进度条的显示"><a href="#1013-进度条的显示" class="headerlink" title="1013: 进度条的显示"></a>1013: 进度条的显示</h2><h2 id="1014-因字数"><a href="#1014-因字数" class="headerlink" title="1014: 因字数"></a>1014: 因字数</h2><h2 id="1015-文章检测"><a href="#1015-文章检测" class="headerlink" title="1015: 文章检测"></a>1015: 文章检测</h2><h2 id="1016-eval-函数的使用2"><a href="#1016-eval-函数的使用2" class="headerlink" title="1016: eval()函数的使用2"></a>1016: eval()函数的使用2</h2><h2 id="1017-质数的和与积"><a href="#1017-质数的和与积" class="headerlink" title="1017: 质数的和与积"></a>1017: 质数的和与积</h2><h2 id="1018-寻找多数元素"><a href="#1018-寻找多数元素" class="headerlink" title="1018: 寻找多数元素"></a>1018: 寻找多数元素</h2><h2 id="1019-判断素数"><a href="#1019-判断素数" class="headerlink" title="1019: 判断素数"></a>1019: 判断素数</h2><h2 id="1020-所有参数的乘积"><a href="#1020-所有参数的乘积" class="headerlink" title="1020: 所有参数的乘积"></a>1020: 所有参数的乘积</h2>]]></content>
    
    
    <categories>
      
      <category>Python学习笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>XDOJ</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
